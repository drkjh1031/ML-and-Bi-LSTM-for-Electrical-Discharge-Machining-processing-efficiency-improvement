# train_models_full.py
# ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµë§Œ ì§„í–‰ (í…ŒìŠ¤íŠ¸ ë¶„ë¦¬ ì—†ìŒ)

import json, time
from pathlib import Path
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
import joblib

# tqdm optional
try:
    from tqdm.auto import tqdm
except Exception:
    tqdm = None

# ===== ê²½ë¡œ =====
OUT_DIR  = Path(
    r"C:\Users\PREMA\Desktop\ì§„í•˜\ML-and-Bi-LSTM-for-Electrical-Discharge-Machining-processing-efficiency-improvement\compareModels\ML"
)
DATA_CSV = Path(r"C:\Users\PREMA\Desktop\ì§„í•˜\ML-and-Bi-LSTM-for-Electrical-Discharge-Machining-processing-efficiency-improvement\compareModels\ML_dataset.csv")
OUT_DIR.mkdir(parents=True, exist_ok=True)

print("[i] ë°ì´í„° ë¡œë”©:", DATA_CSV)
df = pd.read_csv(DATA_CSV)

# ===== ğŸ”§ ë¼ë²¨ ë§¤í•‘ ì¶”ê°€ =====
LABEL_MAP = {
    "Hold": 0,
    "Go":   1,
    "Back": 2
}
ID_TO_LABEL = {v: k for k, v in LABEL_MAP.items()}

# Labelì´ ë¬¸ìì—´ì´ë©´ ìˆ«ìë¡œ ë³€í™˜
if df["Label"].dtype == object:
    df["Label"] = df["Label"].map(LABEL_MAP)

# ì•ˆì „ ì²´í¬
if df["Label"].isnull().any():
    raise ValueError("âŒ Label ì»¬ëŸ¼ì— ë§¤í•‘ë˜ì§€ ì•Šì€ ê°’ì´ ìˆìŠµë‹ˆë‹¤.")

df["Label"] = df["Label"].astype(int)

print("[i] ë¼ë²¨ ë§¤í•‘ í™•ì¸:", df["Label"].value_counts().sort_index().to_dict())

# ===== ì…ë ¥/ì¶œë ¥ ë°ì´í„° =====
feat_cols = ["Max", "Min", "Mean", "Std", "Median", "IQR", "RMS", "Skewness", "Kurtosis"]
X = df[feat_cols].astype(np.float32).values
y = df["Label"].values

print(f"[i] ì „ì²´ ìƒ˜í”Œ ìˆ˜: {len(df):,}, íŠ¹ì„± ìˆ˜: {len(feat_cols)}")

# ===== í•™ìŠµ ë°ì´í„° (ì „ì²´ ì‚¬ìš©) =====
X_tr, y_tr = X, y

# ===== ëª¨ë¸ ì •ì˜ =====
models = {
    "rf": Pipeline([
        ("scaler", StandardScaler()),
        ("clf", RandomForestClassifier(
            n_estimators=200,
            random_state=42,
            class_weight="balanced",
            n_jobs=-1
        ))
    ]),
    "knn": Pipeline([
        ("scaler", StandardScaler()),
        ("clf", KNeighborsClassifier(n_neighbors=5, weights="distance"))
    ]),
    "dt": Pipeline([
        ("scaler", StandardScaler()),
        ("clf", DecisionTreeClassifier(
            max_depth=None,
            random_state=42,
            class_weight="balanced"
        ))
    ]),
    "nb": Pipeline([
        ("scaler", StandardScaler()),
        ("clf", GaussianNB())
    ]),
    "svm": Pipeline([
        ("scaler", StandardScaler()),
        ("clf", LinearSVC(
            C=1.0,
            class_weight="balanced",
            dual=False,
            max_iter=10000,
            random_state=42
        ))
    ]),
}

# ===== í•™ìŠµ ë° ì €ì¥ =====
iterator = list(models.items())
if tqdm:
    iterator = tqdm(iterator, desc="ëª¨ë¸ í•™ìŠµ", unit="model")

for name, pipe in iterator:
    t0 = time.time()
    if tqdm:
        iterator.set_postfix_str(name)

    pipe.fit(X_tr, y_tr)

    took = time.time() - t0
    print(f"=== {name} === í•™ìŠµ ì™„ë£Œ ({took:.2f}s)")

    joblib.dump(
        pipe,
        OUT_DIR / f"1223model_{name}.joblib",
        compress=("xz", 5)
    )

# ===== ë©”íƒ€ ì •ë³´ ì €ì¥ =====
meta = {
    "features": feat_cols,
    "label_map": LABEL_MAP,
    "models": list(models.keys()),
    "created_at": time.ctime(),
}
with open(OUT_DIR / "models_meta.json", "w", encoding="utf-8") as f:
    json.dump(meta, f, ensure_ascii=False, indent=2)

print(" ëª¨ë“  ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ")
